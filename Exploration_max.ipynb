{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# QRT Challenge - Exploratory Data Analysis\n",
    "\n",
    "**Goal**: Predict the sign of an allocation's next-day return (binary classification)\n",
    "\n",
    "**Features**:\n",
    "- `RET_1` to `RET_20`: 20-day history of allocation returns (RET_1 = yesterday)\n",
    "- `SIGNED_VOLUME_1` to `SIGNED_VOLUME_20`: 20-day history of volume-weighted liquidity\n",
    "- `MEDIAN_DAILY_TURNOVER`: Allocation's median daily turnover\n",
    "- `GROUP`: Anonymized allocation group\n",
    "- `ALLOCATION`: Allocation identifier\n",
    "\n",
    "**Target**: `TARGET` - next day return (we predict the sign: 1 if positive, 0 if negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data (faster for EDA)\n",
    "X_train = pd.read_csv('Data/X_train_sample.csv')\n",
    "y_train = pd.read_csv('Data/y_train_sample.csv')\n",
    "\n",
    "# Merge for easier analysis\n",
    "df = X_train.merge(y_train, on='ROW_ID')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "## 1. Basic Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-info",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "print(\"=\" * 50)\n",
    "print(\"DATA TYPES\")\n",
    "print(\"=\" * 50)\n",
    "print(df.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"MISSING VALUES\")\n",
    "print(\"=\" * 50)\n",
    "missing = df.isnull().sum()\n",
    "print(missing[missing > 0])\n",
    "print(f\"\\nTotal missing: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "head-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "describe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for return columns\n",
    "ret_cols = [f'RET_{i}' for i in range(1, 21)]\n",
    "df[ret_cols + ['TARGET']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "## 2. Target Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "target-dist",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Target distribution (continuous)\n",
    "axes[0].hist(df['TARGET'], bins=100, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(0, color='red', linestyle='--', label='Zero')\n",
    "axes[0].set_xlabel('TARGET (Next-day Return)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Target Returns')\n",
    "axes[0].legend()\n",
    "\n",
    "# Binary target (what we predict)\n",
    "df['TARGET_SIGN'] = (df['TARGET'] > 0).astype(int)\n",
    "target_counts = df['TARGET_SIGN'].value_counts()\n",
    "axes[1].bar(['Negative (0)', 'Positive (1)'], [target_counts[0], target_counts[1]], \n",
    "            color=['salmon', 'lightgreen'], edgecolor='black')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title(f'Target Sign Distribution\\n(Positive: {target_counts[1]/len(df)*100:.1f}%)')\n",
    "\n",
    "# Box plot of target by sign\n",
    "axes[2].boxplot([df[df['TARGET'] < 0]['TARGET'], df[df['TARGET'] > 0]['TARGET']], \n",
    "                labels=['Negative', 'Positive'])\n",
    "axes[2].set_ylabel('Return Value')\n",
    "axes[2].set_title('Target Value Distribution by Sign')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Class balance: {target_counts[1]/len(df)*100:.2f}% positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "## 3. Return Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ret-distributions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of returns across different lags\n",
    "fig, axes = plt.subplots(2, 5, figsize=(18, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate([f'RET_{j}' for j in [1, 2, 3, 4, 5, 10, 15, 20]] + ['TARGET']):\n",
    "    if i < len(axes):\n",
    "        axes[i].hist(df[col].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "        axes[i].axvline(0, color='red', linestyle='--', alpha=0.5)\n",
    "        axes[i].set_title(f'{col}\\nmean={df[col].mean():.5f}')\n",
    "        axes[i].set_xlabel('Return')\n",
    "\n",
    "# Hide the last empty subplot\n",
    "axes[-1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ret-stats-over-time",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do return statistics change across lags?\n",
    "ret_stats = pd.DataFrame({\n",
    "    'lag': range(1, 21),\n",
    "    'mean': [df[f'RET_{i}'].mean() for i in range(1, 21)],\n",
    "    'std': [df[f'RET_{i}'].std() for i in range(1, 21)],\n",
    "    'skew': [df[f'RET_{i}'].skew() for i in range(1, 21)],\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(ret_stats['lag'], ret_stats['mean'], marker='o')\n",
    "axes[0].axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[0].set_xlabel('Lag (days ago)')\n",
    "axes[0].set_ylabel('Mean Return')\n",
    "axes[0].set_title('Mean Return by Lag')\n",
    "\n",
    "axes[1].plot(ret_stats['lag'], ret_stats['std'], marker='o', color='orange')\n",
    "axes[1].set_xlabel('Lag (days ago)')\n",
    "axes[1].set_ylabel('Std Return')\n",
    "axes[1].set_title('Return Volatility by Lag')\n",
    "\n",
    "axes[2].plot(ret_stats['lag'], ret_stats['skew'], marker='o', color='green')\n",
    "axes[2].axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[2].set_xlabel('Lag (days ago)')\n",
    "axes[2].set_ylabel('Skewness')\n",
    "axes[2].set_title('Return Skewness by Lag')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "## 4. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correlation-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of each feature with TARGET\n",
    "ret_cols = [f'RET_{i}' for i in range(1, 21)]\n",
    "vol_cols = [f'SIGNED_VOLUME_{i}' for i in range(1, 21)]\n",
    "\n",
    "ret_corr = df[ret_cols + ['TARGET']].corr()['TARGET'].drop('TARGET')\n",
    "vol_corr = df[vol_cols + ['TARGET']].corr()['TARGET'].drop('TARGET')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Return correlations\n",
    "axes[0].bar(range(1, 21), ret_corr.values, color='steelblue', edgecolor='black')\n",
    "axes[0].axhline(0, color='red', linestyle='--')\n",
    "axes[0].set_xlabel('Lag (days ago)')\n",
    "axes[0].set_ylabel('Correlation with TARGET')\n",
    "axes[0].set_title('RET_i Correlation with Target')\n",
    "axes[0].set_xticks(range(1, 21))\n",
    "\n",
    "# Volume correlations\n",
    "axes[1].bar(range(1, 21), vol_corr.values, color='darkorange', edgecolor='black')\n",
    "axes[1].axhline(0, color='red', linestyle='--')\n",
    "axes[1].set_xlabel('Lag (days ago)')\n",
    "axes[1].set_ylabel('Correlation with TARGET')\n",
    "axes[1].set_title('SIGNED_VOLUME_i Correlation with Target')\n",
    "axes[1].set_xticks(range(1, 21))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 5 RET correlations with TARGET:\")\n",
    "print(ret_corr.abs().sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correlation-heatmap",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap for return features\n",
    "plt.figure(figsize=(14, 10))\n",
    "corr_matrix = df[ret_cols + ['TARGET']].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='RdBu_r', center=0, \n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Correlation Matrix: Return Features + Target')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "## 5. Group Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "group-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many groups? How are samples distributed?\n",
    "print(f\"Number of unique GROUPs: {df['GROUP'].nunique()}\")\n",
    "print(f\"Number of unique ALLOCATIONs: {df['ALLOCATION'].nunique()}\")\n",
    "print(f\"Number of unique timestamps: {df['TS'].nunique()}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Samples per group\n",
    "group_counts = df['GROUP'].value_counts().sort_index()\n",
    "axes[0].bar(group_counts.index, group_counts.values, edgecolor='black')\n",
    "axes[0].set_xlabel('GROUP')\n",
    "axes[0].set_ylabel('Number of Samples')\n",
    "axes[0].set_title('Sample Distribution by GROUP')\n",
    "\n",
    "# Target mean by group\n",
    "group_target = df.groupby('GROUP')['TARGET'].agg(['mean', 'std'])\n",
    "axes[1].bar(group_target.index, group_target['mean'], yerr=group_target['std']/10, \n",
    "            edgecolor='black', capsize=3)\n",
    "axes[1].axhline(0, color='red', linestyle='--')\n",
    "axes[1].set_xlabel('GROUP')\n",
    "axes[1].set_ylabel('Mean Target Return')\n",
    "axes[1].set_title('Mean Target by GROUP (error bars = std/10)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "group-win-rate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Win rate (positive return %) by group\n",
    "group_win_rate = df.groupby('GROUP')['TARGET_SIGN'].mean() * 100\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "bars = plt.bar(group_win_rate.index, group_win_rate.values, edgecolor='black')\n",
    "plt.axhline(50, color='red', linestyle='--', label='50% baseline')\n",
    "plt.xlabel('GROUP')\n",
    "plt.ylabel('Win Rate (%)')\n",
    "plt.title('Positive Return Rate by GROUP')\n",
    "plt.legend()\n",
    "\n",
    "# Color bars based on win rate\n",
    "for bar, rate in zip(bars, group_win_rate.values):\n",
    "    bar.set_color('lightgreen' if rate > 50 else 'salmon')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Win rate by GROUP:\")\n",
    "print(group_win_rate.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6",
   "metadata": {},
   "source": [
    "## 6. Turnover Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turnover-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Turnover distribution\n",
    "axes[0].hist(df['MEDIAN_DAILY_TURNOVER'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Median Daily Turnover')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Turnover')\n",
    "\n",
    "# Turnover vs Target (scatter)\n",
    "sample_idx = np.random.choice(len(df), min(5000, len(df)), replace=False)\n",
    "axes[1].scatter(df.iloc[sample_idx]['MEDIAN_DAILY_TURNOVER'], \n",
    "                df.iloc[sample_idx]['TARGET'], alpha=0.3, s=10)\n",
    "axes[1].axhline(0, color='red', linestyle='--')\n",
    "axes[1].set_xlabel('Median Daily Turnover')\n",
    "axes[1].set_ylabel('Target Return')\n",
    "axes[1].set_title('Turnover vs Target')\n",
    "\n",
    "# Turnover by group\n",
    "df.boxplot(column='MEDIAN_DAILY_TURNOVER', by='GROUP', ax=axes[2])\n",
    "axes[2].set_xlabel('GROUP')\n",
    "axes[2].set_ylabel('Median Daily Turnover')\n",
    "axes[2].set_title('Turnover Distribution by GROUP')\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation\n",
    "print(f\"Correlation between TURNOVER and TARGET: {df['MEDIAN_DAILY_TURNOVER'].corr(df['TARGET']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7",
   "metadata": {},
   "source": [
    "## 7. RET_1 Deep Dive (Most Important Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ret1-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RET_1 appears to be the most predictive feature - let's analyze it\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# RET_1 vs TARGET scatter\n",
    "sample_idx = np.random.choice(len(df), min(5000, len(df)), replace=False)\n",
    "axes[0].scatter(df.iloc[sample_idx]['RET_1'], df.iloc[sample_idx]['TARGET'], \n",
    "                alpha=0.3, s=10)\n",
    "axes[0].axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[0].axvline(0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[0].set_xlabel('RET_1 (Yesterday Return)')\n",
    "axes[0].set_ylabel('TARGET (Today Return)')\n",
    "axes[0].set_title(f'RET_1 vs TARGET\\nCorr: {df[\"RET_1\"].corr(df[\"TARGET\"]):.4f}')\n",
    "\n",
    "# Win rate by RET_1 quintile\n",
    "df['RET_1_quintile'] = pd.qcut(df['RET_1'], 5, labels=['Q1(Low)', 'Q2', 'Q3', 'Q4', 'Q5(High)'])\n",
    "quintile_win_rate = df.groupby('RET_1_quintile')['TARGET_SIGN'].mean() * 100\n",
    "axes[1].bar(quintile_win_rate.index, quintile_win_rate.values, edgecolor='black')\n",
    "axes[1].axhline(50, color='red', linestyle='--')\n",
    "axes[1].set_xlabel('RET_1 Quintile')\n",
    "axes[1].set_ylabel('Win Rate (%)')\n",
    "axes[1].set_title('Win Rate by RET_1 Quintile')\n",
    "\n",
    "# Mean target by RET_1 quintile\n",
    "quintile_mean = df.groupby('RET_1_quintile')['TARGET'].mean() * 100  # in bps\n",
    "colors = ['salmon' if x < 0 else 'lightgreen' for x in quintile_mean.values]\n",
    "axes[2].bar(quintile_mean.index, quintile_mean.values, color=colors, edgecolor='black')\n",
    "axes[2].axhline(0, color='red', linestyle='--')\n",
    "axes[2].set_xlabel('RET_1 Quintile')\n",
    "axes[2].set_ylabel('Mean Target Return (bps)')\n",
    "axes[2].set_title('Mean Target by RET_1 Quintile')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Clean up\n",
    "df.drop('RET_1_quintile', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "momentum-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there momentum or mean reversion?\n",
    "# Momentum: RET_1 positive -> TARGET positive (same sign)\n",
    "# Mean reversion: RET_1 positive -> TARGET negative (opposite sign)\n",
    "\n",
    "df['RET_1_SIGN'] = (df['RET_1'] > 0).astype(int)\n",
    "\n",
    "cross_tab = pd.crosstab(df['RET_1_SIGN'], df['TARGET_SIGN'], normalize='index') * 100\n",
    "cross_tab.index = ['RET_1 < 0', 'RET_1 > 0']\n",
    "cross_tab.columns = ['TARGET < 0', 'TARGET > 0']\n",
    "\n",
    "print(\"Conditional probabilities (%):\\n\")\n",
    "print(cross_tab.round(2))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Interpretation\n",
    "momentum_evidence = cross_tab.loc['RET_1 > 0', 'TARGET > 0'] > cross_tab.loc['RET_1 < 0', 'TARGET > 0']\n",
    "print(f\"Evidence of MOMENTUM: {momentum_evidence}\")\n",
    "print(f\"If RET_1 > 0: {cross_tab.loc['RET_1 > 0', 'TARGET > 0']:.1f}% chance TARGET > 0\")\n",
    "print(f\"If RET_1 < 0: {cross_tab.loc['RET_1 < 0', 'TARGET > 0']:.1f}% chance TARGET > 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-8",
   "metadata": {},
   "source": [
    "## 8. Volume Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "volume-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_cols = [f'SIGNED_VOLUME_{i}' for i in range(1, 21)]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Volume distribution for recent days\n",
    "for col in ['SIGNED_VOLUME_1', 'SIGNED_VOLUME_5', 'SIGNED_VOLUME_10', 'SIGNED_VOLUME_20']:\n",
    "    axes[0].hist(df[col].dropna(), bins=50, alpha=0.5, label=col)\n",
    "axes[0].set_xlabel('Signed Volume')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Signed Volume')\n",
    "axes[0].legend()\n",
    "\n",
    "# Volume stats over time\n",
    "vol_means = [df[f'SIGNED_VOLUME_{i}'].mean() for i in range(1, 21)]\n",
    "vol_stds = [df[f'SIGNED_VOLUME_{i}'].std() for i in range(1, 21)]\n",
    "\n",
    "axes[1].errorbar(range(1, 21), vol_means, yerr=np.array(vol_stds)/10, \n",
    "                 marker='o', capsize=3)\n",
    "axes[1].axhline(0, color='red', linestyle='--')\n",
    "axes[1].set_xlabel('Lag (days ago)')\n",
    "axes[1].set_ylabel('Mean Signed Volume')\n",
    "axes[1].set_title('Signed Volume by Lag (error = std/10)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-9",
   "metadata": {},
   "source": [
    "## 9. Feature Engineering Ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test some potential engineered features\n",
    "df_fe = df.copy()\n",
    "\n",
    "# Rolling statistics\n",
    "ret_cols = [f'RET_{i}' for i in range(1, 21)]\n",
    "df_fe['RET_MEAN_5'] = df_fe[[f'RET_{i}' for i in range(1, 6)]].mean(axis=1)\n",
    "df_fe['RET_MEAN_20'] = df_fe[ret_cols].mean(axis=1)\n",
    "df_fe['RET_STD_5'] = df_fe[[f'RET_{i}' for i in range(1, 6)]].std(axis=1)\n",
    "df_fe['RET_STD_20'] = df_fe[ret_cols].std(axis=1)\n",
    "\n",
    "# Cumulative return\n",
    "df_fe['RET_CUM_5'] = df_fe[[f'RET_{i}' for i in range(1, 6)]].sum(axis=1)\n",
    "df_fe['RET_CUM_20'] = df_fe[ret_cols].sum(axis=1)\n",
    "\n",
    "# Momentum indicators\n",
    "df_fe['RET_POSITIVE_COUNT_5'] = (df_fe[[f'RET_{i}' for i in range(1, 6)]] > 0).sum(axis=1)\n",
    "df_fe['RET_POSITIVE_COUNT_20'] = (df_fe[ret_cols] > 0).sum(axis=1)\n",
    "\n",
    "# Recent vs old\n",
    "df_fe['RET_RECENT_VS_OLD'] = df_fe['RET_MEAN_5'] - df_fe[[f'RET_{i}' for i in range(16, 21)]].mean(axis=1)\n",
    "\n",
    "# Check correlations with target\n",
    "new_features = ['RET_MEAN_5', 'RET_MEAN_20', 'RET_STD_5', 'RET_STD_20', \n",
    "                'RET_CUM_5', 'RET_CUM_20', 'RET_POSITIVE_COUNT_5', \n",
    "                'RET_POSITIVE_COUNT_20', 'RET_RECENT_VS_OLD']\n",
    "\n",
    "correlations = df_fe[new_features + ['TARGET']].corr()['TARGET'].drop('TARGET')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "colors = ['lightgreen' if x > 0 else 'salmon' for x in correlations.values]\n",
    "plt.barh(correlations.index, correlations.values, color=colors, edgecolor='black')\n",
    "plt.axvline(0, color='black', linestyle='-')\n",
    "plt.xlabel('Correlation with TARGET')\n",
    "plt.title('Engineered Features: Correlation with Target')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEngineered feature correlations:\")\n",
    "print(correlations.sort_values(ascending=False).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-10",
   "metadata": {},
   "source": [
    "## 10. Key Takeaways\n",
    "\n",
    "### Summary of findings:\n",
    "\n",
    "1. **Target Balance**: Check if classes are balanced (~50/50 split)\n",
    "\n",
    "2. **RET_1 is dominant**: Yesterday's return is by far the most predictive feature\n",
    "\n",
    "3. **Momentum vs Mean Reversion**: Analyze the conditional probabilities to determine the regime\n",
    "\n",
    "4. **Group differences**: Some groups may have systematically different win rates\n",
    "\n",
    "5. **Feature engineering**: Rolling means, cumulative returns, and momentum indicators may help\n",
    "\n",
    "6. **Volume features**: Generally weaker predictors than return features\n",
    "\n",
    "### Next steps:\n",
    "- Build baseline models (Logistic Regression, Random Forest, XGBoost)\n",
    "- Feature selection based on importance\n",
    "- Cross-validation strategy (careful with time-series aspects)\n",
    "- Ensemble methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
